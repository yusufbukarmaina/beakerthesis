# ğŸ§ª Beaker Volume Detection using Vision-Language Models

This project uses fine-tuned Vision-Language Models (Florence-2 and Qwen2-VL) to detect beaker capacity and liquid volume from images.

## ğŸ“‹ Project Overview

- **Dataset**: 2000+ beaker images from Hugging Face (`yusufbukarmaina/Beakers1`)
- **Beaker Types**: 100mL and 250mL
- **Viewpoints**: Left, Right, Above, Below, Front
- **Backgrounds**: Controlled and Uncontrolled
- **Models**: Florence-2 and Qwen2-VL (fine-tuned with LoRA)
- **Hardware**: Optimized for JarvisLab A100 (40GB)

## ğŸš€ Quick Start

### 1. Installation
```bash
chmod +x setup.sh
./setup.sh
```

Or manually install:
```bash
pip install -r requirements.txt
```

### 2. Data Preparation
```bash
python data_utils1.py
```

This will:
- Load the dataset from Hugging Face
- Split into train (70%), validation (15%), test (15%)
- Save test data to `outputs/test_data/`

### 3. Training

**Train Florence-2:**
```bash
python train_florence1.py
```

**Train Qwen2-VL:**
```bash
python train_qwen1.py
```

Models will be saved to:
- `outputs/florence2/final_model/`
- `outputs/qwen2vl/final_model/`

### 4. Evaluation
```bash
python evaluate1.py
```

This generates:
- MAE, RMSE, RÂ² metrics for both models
- Comparison visualizations
- Performance analysis by viewpoint and background

Results saved to `outputs/results/`

### 5. Demo

**Launch Gradio Interface:**
```bash
python demo1.py
```

**Single Image Inference:**
```bash
python inference.py path/to/image.jpg --model florence
python inference.py path/to/image.jpg --model qwen
```

## ğŸ“ Project Structure
```
beaker_project/
â”œâ”€â”€ config.py                 # Configuration settings
â”œâ”€â”€ data_utils.py            # Data loading and processing
â”œâ”€â”€ train_florence.py        # Florence-2 training script
â”œâ”€â”€ train_qwen.py            # Qwen2-VL training script
â”œâ”€â”€ evaluate.py              # Model evaluation
â”œâ”€â”€ demo.py                  # Gradio interface
â”œâ”€â”€ inference.py             # Single image inference
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ setup.sh                 # Setup script
â”œâ”€â”€ README.md               # This file
â””â”€â”€ outputs/
    â”œâ”€â”€ florence2/          # Florence-2 checkpoints
    â”œâ”€â”€ qwen2vl/           # Qwen2-VL checkpoints
    â”œâ”€â”€ test_data/         # Test images and metadata
    â””â”€â”€ results/           # Evaluation results and plots
```

## ğŸ”§ Configuration

Edit `config.py` to customize:
- Batch sizes
- Learning rates
- Number of epochs
- LoRA parameters
- Output directories

**Default settings for A100 40GB:**
- Florence-2: batch_size=4, gradient_accumulation=4
- Qwen2-VL: batch_size=2, gradient_accumulation=8

## ğŸ“Š Evaluation Metrics

Both models are evaluated using:
- **MAE** (Mean Absolute Error): Average prediction error in mL
- **RMSE** (Root Mean Squared Error): Penalizes larger errors
- **RÂ²** (R-squared): Goodness of fit (0 to 1, higher is better)

Additional metrics:
- Beaker capacity classification accuracy
- Performance by viewpoint
- Performance by background type

## ğŸ¯ Expected Performance

Target metrics (will vary based on training):
- MAE: < 5 mL
- RMSE: < 10 mL
- RÂ²: > 0.95
- Beaker Accuracy: > 98%

## ğŸ’¾ Test Data Download

After running `data_utils.py` or any training script, test data is saved to:
```
outputs/test_data/
â”œâ”€â”€ images/          # Test images
â”œâ”€â”€ metadata.json    # Image metadata
â””â”€â”€ README.txt       # Dataset info
```

You can download this folder for demo purposes.

## ğŸ› Troubleshooting

**Out of Memory Error:**
- Reduce batch size in `config.py`
- Increase gradient accumulation steps
- Use smaller LoRA rank

**Model Loading Issues:**
- Ensure models are trained before evaluation/demo
- Check model paths in `config.py`
- Verify HuggingFace cache has space

**Dataset Loading Issues:**
- Check internet connection
- Verify HuggingFace dataset name
- Clear cache: `rm -rf ~/.cache/huggingface/`

## ğŸ“ Citation

If you use this code, please cite:
```bibtex
@misc{beaker-volume-detection,
  author = {Your Name},
  title = {Beaker Volume Detection using Vision-Language Models},
  year = {2026},
  publisher = {GitHub},
  url = {https://github.com/yourusername/beaker-volume-detection}
}
```

## ğŸ“„ License

MIT License - feel free to use for research and commercial purposes.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit issues or pull requests.

## ğŸ“§ Contact

For questions or issues, please open a GitHub issue or contact [your-email@example.com]
```

### **11. .gitignore**
```
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual environments
venv/
ENV/
env/

# Jupyter Notebook
.ipynb_checkpoints

# IDEs
.vscode/
.idea/
*.swp
*.swo

# Model outputs
outputs/
*.pt
*.pth
*.bin
*.safetensors

# Logs
*.log
logs/
tensorboard/
wandb/

# Data
data/
*.csv
*.json
!requirements.txt
!config.py

# OS
.DS_Store
Thumbs.db

# HuggingFace cache

.cache/
